{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "06BYdN-FCU7t",
        "outputId": "0ad180f9-9e02-40b1-bbc9-13eddd0b6b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "06BYdN-FCU7t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./drive/MyDrive/CS5242_project/personal_testing/data"
      ],
      "metadata": {
        "id": "Hmbdrt3MCr_v",
        "outputId": "a3755f6e-e553-4bdb-b857-eec940f6ac2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Hmbdrt3MCr_v",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CAM16_100cls_10mask  pRCC_nolabel  WBC_1  WBC_10  WBC_100  WBC_50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "54fea732-6b12-4e0c-a376-a14fadec80bf",
      "metadata": {
        "id": "54fea732-6b12-4e0c-a376-a14fadec80bf",
        "outputId": "710be1fa-ca71-4796-be33-d4689f1bf547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Pretraining Epoch 1/1:   0%|          | 0/45 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 3, 224, 224])) that is different to the input size (torch.Size([32, 128, 112, 112])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Pretraining Epoch 1/1:   0%|          | 0/45 [00:11<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.1622, 0.0832, 0.0000],\n",
            "          [0.0085, 0.0000, 0.0000,  ..., 0.1300, 0.1079, 0.0153],\n",
            "          [0.0000, 0.0015, 0.0000,  ..., 0.2059, 0.1597, 0.1586],\n",
            "          ...,\n",
            "          [0.1588, 0.0280, 0.0095,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.2178, 0.1487, 0.1312,  ..., 0.0176, 0.0000, 0.0000],\n",
            "          [0.0560, 0.1284, 0.2810,  ..., 0.2214, 0.0283, 0.0529]],\n",
            "\n",
            "         [[0.3420, 0.4179, 0.4244,  ..., 0.4156, 0.3216, 0.2450],\n",
            "          [0.2059, 0.3021, 0.2909,  ..., 0.4487, 0.4385, 0.2127],\n",
            "          [0.2510, 0.2672, 0.2730,  ..., 0.0872, 0.1284, 0.2818],\n",
            "          ...,\n",
            "          [0.0660, 0.2144, 0.3013,  ..., 0.3021, 0.4009, 0.3834],\n",
            "          [0.2319, 0.1687, 0.0893,  ..., 0.1202, 0.3992, 0.4479],\n",
            "          [0.1582, 0.1588, 0.1469,  ..., 0.2260, 0.1292, 0.3464]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.1014, 0.1772, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0618, 0.0092, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0007, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0124, 0.0000],\n",
            "          ...,\n",
            "          [0.0230, 0.0000, 0.0000,  ..., 0.0435, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0463, 0.0000, 0.1775,  ..., 0.0375, 0.0124, 0.1203]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.3121, 0.3010, 0.1896],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1181],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0688, 0.0000, 0.0256],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0427, 0.0000,  ..., 0.0280, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0686, 0.0200, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0243],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0415,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0607, 0.1285,  ..., 0.0315, 0.0000, 0.0405],\n",
            "          [0.0000, 0.0000, 0.0217,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.1752, 0.2524, 0.0361,  ..., 0.1354, 0.0402, 0.0120],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.1904, 0.1599, 0.0235],\n",
            "          [0.0000, 0.0000, 0.1670,  ..., 0.0511, 0.0896, 0.0720]],\n",
            "\n",
            "         [[0.3683, 0.2809, 0.3936,  ..., 0.1305, 0.1208, 0.3282],\n",
            "          [0.3408, 0.2228, 0.0000,  ..., 0.3479, 0.3092, 0.1138],\n",
            "          [0.3835, 0.2638, 0.3672,  ..., 0.5344, 0.5030, 0.3457],\n",
            "          ...,\n",
            "          [0.1029, 0.0732, 0.2877,  ..., 0.1348, 0.2471, 0.3487],\n",
            "          [0.3124, 0.3298, 0.2717,  ..., 0.4566, 0.0950, 0.1226],\n",
            "          [0.1706, 0.3495, 0.3034,  ..., 0.1334, 0.2768, 0.1762]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0074, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0939, 0.2136,  ..., 0.1333, 0.0000, 0.0000],\n",
            "          [0.0000, 0.1091, 0.0000,  ..., 0.0191, 0.0256, 0.0858],\n",
            "          ...,\n",
            "          [0.0000, 0.0528, 0.0000,  ..., 0.0154, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0186, 0.0105,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0639, 0.1066, 0.2197,  ..., 0.0228, 0.0604, 0.0587]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0415, 0.0000, 0.0278,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.1333, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.1100, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0073, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0267, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1081, 0.0406]],\n",
            "\n",
            "         [[0.6566, 0.6047, 0.4787,  ..., 0.5060, 0.4214, 0.5037],\n",
            "          [0.3687, 0.4635, 0.5124,  ..., 0.2813, 0.3021, 0.3848],\n",
            "          [0.4358, 0.3347, 0.3555,  ..., 0.4017, 0.3486, 0.4514],\n",
            "          ...,\n",
            "          [0.5481, 0.5826, 0.5227,  ..., 0.3451, 0.2096, 0.3976],\n",
            "          [0.5459, 0.5651, 0.5452,  ..., 0.4361, 0.2926, 0.2067],\n",
            "          [0.3026, 0.4667, 0.4496,  ..., 0.2845, 0.3785, 0.2916]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.1293, 0.0911, 0.0000,  ..., 0.0304, 0.0000, 0.0000],\n",
            "          [0.0185, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0232, 0.0219, 0.0547,  ..., 0.0281, 0.0081, 0.0339],\n",
            "          [0.0199, 0.0371, 0.0504,  ..., 0.0000, 0.0055, 0.0559],\n",
            "          [0.1511, 0.1526, 0.1616,  ..., 0.0999, 0.0000, 0.0345]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0904, 0.1803, 0.2080,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0362, 0.1301, 0.2885,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.4620, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.1892, 0.0000, 0.0774]],\n",
            "\n",
            "         [[0.2340, 0.2723, 0.1666,  ..., 0.6160, 0.6303, 0.6157],\n",
            "          [0.2501, 0.1906, 0.2079,  ..., 0.5443, 0.5569, 0.5840],\n",
            "          [0.2601, 0.5981, 0.2293,  ..., 0.5512, 0.5466, 0.6228],\n",
            "          ...,\n",
            "          [0.4696, 0.5258, 0.5712,  ..., 0.3351, 0.1388, 0.3070],\n",
            "          [0.5304, 0.5572, 0.5153,  ..., 0.4979, 0.3371, 0.3472],\n",
            "          [0.3047, 0.3975, 0.4280,  ..., 0.4492, 0.3895, 0.3783]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0130,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0016, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0698, 0.0000, 0.0618,  ..., 0.0502, 0.0365, 0.0744],\n",
            "          [0.0000, 0.0000, 0.1381,  ..., 0.0219, 0.0417, 0.0706],\n",
            "          ...,\n",
            "          [0.0000, 0.0396, 0.0032,  ..., 0.2188, 0.1038, 0.0000],\n",
            "          [0.0177, 0.0133, 0.0202,  ..., 0.0000, 0.0000, 0.0136],\n",
            "          [0.1375, 0.1563, 0.1414,  ..., 0.4090, 0.2427, 0.2762]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0309, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0444],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0090, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0578, 0.1796, 0.1009,  ..., 0.1215, 0.1746, 0.2225],\n",
            "          [0.1308, 0.1193, 0.0800,  ..., 0.2226, 0.1433, 0.1265],\n",
            "          ...,\n",
            "          [0.0000, 0.0049, 0.2830,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0810,  ..., 0.1216, 0.0795, 0.1991],\n",
            "          [0.0373, 0.0267, 0.2120,  ..., 0.2646, 0.2080, 0.2953]],\n",
            "\n",
            "         [[0.1657, 0.2007, 0.2677,  ..., 0.2511, 0.2252, 0.2436],\n",
            "          [0.1704, 0.1813, 0.0923,  ..., 0.1429, 0.3057, 0.2278],\n",
            "          [0.1913, 0.2352, 0.2173,  ..., 0.3223, 0.2699, 0.2144],\n",
            "          ...,\n",
            "          [0.4343, 0.5278, 0.4226,  ..., 0.5542, 0.4700, 0.4924],\n",
            "          [0.4528, 0.5282, 0.3878,  ..., 0.0506, 0.2590, 0.3126],\n",
            "          [0.2579, 0.4192, 0.2801,  ..., 0.3147, 0.2592, 0.2027]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0037, 0.0055, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0372,  ..., 0.0000, 0.0024, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0802, 0.2019,  ..., 0.0044, 0.1523, 0.2041],\n",
            "          [0.0000, 0.0236, 0.2514,  ..., 0.1297, 0.1877, 0.1329],\n",
            "          [0.1167, 0.1249, 0.1593,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0522, 0.0494, 0.0655],\n",
            "          [0.0000, 0.0071, 0.0104,  ..., 0.0000, 0.0000, 0.1679],\n",
            "          [0.0393, 0.0000, 0.0000,  ..., 0.0787, 0.0000, 0.0854],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0208, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0375, 0.1170, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0159, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0617,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.2358, 0.1171, 0.2331,  ..., 0.0000, 0.1221, 0.0958],\n",
            "          [0.0000, 0.0737, 0.1210,  ..., 0.0220, 0.1194, 0.0657],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.1367,  ..., 0.0691, 0.1433, 0.0817],\n",
            "          [0.0000, 0.0000, 0.0377,  ..., 0.1280, 0.1174, 0.0577],\n",
            "          [0.0000, 0.0000, 0.1570,  ..., 0.1438, 0.0797, 0.1222]],\n",
            "\n",
            "         [[0.1544, 0.4875, 0.4133,  ..., 0.5441, 0.2258, 0.3339],\n",
            "          [0.2451, 0.1409, 0.3367,  ..., 0.3598, 0.3170, 0.1122],\n",
            "          [0.3118, 0.2910, 0.1398,  ..., 0.2279, 0.1808, 0.3506],\n",
            "          ...,\n",
            "          [0.3773, 0.2127, 0.2353,  ..., 0.2830, 0.0675, 0.3219],\n",
            "          [0.3897, 0.2394, 0.2401,  ..., 0.1606, 0.2185, 0.2321],\n",
            "          [0.2085, 0.4073, 0.2157,  ..., 0.1052, 0.2188, 0.1975]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0061, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0740, 0.0784, 0.0000],\n",
            "          [0.0000, 0.0023, 0.0000,  ..., 0.0738, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0943,  ..., 0.0000, 0.0341, 0.0811],\n",
            "          [0.0132, 0.1527, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.1170, 0.0085, 0.0011,  ..., 0.0000, 0.0736, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0868],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0028,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0009, 0.0000,  ..., 0.0027, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
            "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
            "tensor([[[[ 1.7624e+00,  1.5134e+00,  1.7042e+00,  ..., -6.7976e-01,\n",
            "            3.5370e-01,  2.6023e-01],\n",
            "          [ 1.6244e+00,  1.7482e+00,  1.6234e+00,  ..., -9.2811e-01,\n",
            "            3.2455e-01,  8.2103e-01],\n",
            "          [ 1.6915e+00,  1.7787e+00,  1.6582e+00,  ..., -1.7122e-01,\n",
            "            1.0755e+00,  1.3406e+00],\n",
            "          ...,\n",
            "          [-1.6075e-01, -6.4403e-01, -4.3327e-01,  ...,  1.7053e+00,\n",
            "            1.4704e+00,  1.7668e+00],\n",
            "          [ 4.8939e-01,  1.1544e-01,  1.9010e-01,  ...,  1.4850e+00,\n",
            "            1.5789e+00,  1.5974e+00],\n",
            "          [ 1.1895e+00,  8.7918e-01,  8.6760e-01,  ...,  1.4580e+00,\n",
            "            1.7695e+00,  1.4571e+00]],\n",
            "\n",
            "         [[ 4.5322e-01,  1.3489e-01,  3.7848e-01,  ..., -1.2498e+00,\n",
            "           -3.2639e-01, -6.8006e-01],\n",
            "          [ 4.5872e-01,  3.9699e-01,  5.3499e-01,  ..., -1.5852e+00,\n",
            "           -5.6901e-01, -5.2723e-01],\n",
            "          [ 2.7627e-01,  5.0689e-01,  2.7614e-01,  ..., -1.1757e+00,\n",
            "           -5.5828e-01, -1.9153e-01],\n",
            "          ...,\n",
            "          [-8.9819e-01, -1.0196e+00, -9.8325e-01,  ...,  1.4587e+00,\n",
            "            1.0873e+00,  1.1882e+00],\n",
            "          [-4.1846e-01, -6.7498e-01, -5.0891e-01,  ...,  1.4733e+00,\n",
            "            1.1917e+00,  1.0497e+00],\n",
            "          [ 1.9574e-01, -2.3540e-01, -2.7669e-01,  ...,  8.3858e-01,\n",
            "            1.1678e+00,  1.1569e+00]],\n",
            "\n",
            "         [[ 1.1600e+00,  1.1621e+00,  1.2365e+00,  ..., -2.0157e-01,\n",
            "            6.8548e-01,  4.0831e-01],\n",
            "          [ 1.3580e+00,  1.2090e+00,  1.1697e+00,  ..., -6.1623e-01,\n",
            "            1.9321e-01,  3.1221e-01],\n",
            "          [ 1.2944e+00,  1.1669e+00,  1.1410e+00,  ...,  1.4849e-02,\n",
            "            6.2357e-01,  1.0254e+00],\n",
            "          ...,\n",
            "          [ 1.8988e-01, -2.6163e-01,  1.0907e-02,  ...,  1.8927e+00,\n",
            "            1.6702e+00,  1.8315e+00],\n",
            "          [ 5.5632e-01,  2.3070e-01,  6.3354e-01,  ...,  1.7269e+00,\n",
            "            1.9549e+00,  1.7270e+00],\n",
            "          [ 1.0493e+00,  5.0291e-01,  7.2216e-01,  ...,  1.3733e+00,\n",
            "            1.6013e+00,  1.7058e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1662e+00,  1.6560e+00, -4.5308e-02,  ...,  8.0757e-01,\n",
            "            1.2722e+00,  1.6287e+00],\n",
            "          [ 1.4545e+00,  1.5804e+00,  2.8267e-01,  ...,  2.8948e-01,\n",
            "            1.2519e+00,  1.4795e+00],\n",
            "          [ 1.3287e+00,  1.1261e+00,  1.1241e+00,  ..., -1.0662e-01,\n",
            "            8.9695e-01,  1.2168e+00],\n",
            "          ...,\n",
            "          [ 2.9086e-01,  1.2269e-01,  2.9852e-01,  ...,  2.6032e-02,\n",
            "            3.3721e-01,  9.6138e-01],\n",
            "          [ 1.4496e+00,  1.5333e+00,  1.7609e+00,  ...,  9.0818e-01,\n",
            "            9.7768e-01,  9.9831e-01],\n",
            "          [ 1.8547e+00,  1.6477e+00,  1.9127e+00,  ...,  1.0951e+00,\n",
            "            1.2163e+00,  1.0245e+00]],\n",
            "\n",
            "         [[ 8.3011e-01,  1.2466e+00, -4.0532e-01,  ...,  3.1734e-01,\n",
            "            1.1141e+00,  1.3115e+00],\n",
            "          [ 8.6385e-01,  1.0215e+00, -1.8299e-01,  ..., -4.6321e-01,\n",
            "            6.1466e-01,  1.2766e+00],\n",
            "          [ 1.3185e+00,  7.2918e-01,  5.3535e-01,  ..., -6.1534e-01,\n",
            "            1.8807e-01,  4.9358e-01],\n",
            "          ...,\n",
            "          [-4.5234e-02, -2.5335e-01, -1.7948e-01,  ..., -7.0790e-01,\n",
            "           -3.7465e-01,  9.8225e-02],\n",
            "          [ 1.2130e+00,  1.1839e+00,  1.4755e+00,  ...,  2.3335e-02,\n",
            "            1.7909e-01,  2.0590e-01],\n",
            "          [ 1.7296e+00,  1.7463e+00,  1.8090e+00,  ...,  4.6040e-01,\n",
            "            4.4663e-01,  3.5462e-01]],\n",
            "\n",
            "         [[ 1.4184e+00,  2.0965e+00,  5.9495e-01,  ...,  1.0379e+00,\n",
            "            1.6279e+00,  1.7771e+00],\n",
            "          [ 1.6997e+00,  1.8925e+00,  6.2381e-01,  ...,  5.9822e-01,\n",
            "            1.4275e+00,  1.6069e+00],\n",
            "          [ 1.7365e+00,  1.4316e+00,  1.3384e+00,  ...,  3.3548e-01,\n",
            "            9.6801e-01,  1.1892e+00],\n",
            "          ...,\n",
            "          [ 8.9004e-01,  5.7525e-01,  7.1437e-01,  ...,  3.8479e-01,\n",
            "            6.1904e-01,  9.1453e-01],\n",
            "          [ 1.9760e+00,  1.5658e+00,  1.7509e+00,  ...,  8.2014e-01,\n",
            "            8.8323e-01,  8.9749e-01],\n",
            "          [ 2.0454e+00,  2.1800e+00,  2.2046e+00,  ...,  1.4372e+00,\n",
            "            1.3262e+00,  9.5730e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0363e+00,  1.9716e+00,  1.9250e+00,  ...,  1.9686e+00,\n",
            "            1.7824e+00,  1.9577e+00],\n",
            "          [ 2.0126e+00,  1.9711e+00,  1.8921e+00,  ...,  1.4663e+00,\n",
            "            1.4516e+00,  1.6025e+00],\n",
            "          [ 2.0840e+00,  1.9774e+00,  1.9691e+00,  ...,  1.3729e+00,\n",
            "            1.3612e+00,  1.3531e+00],\n",
            "          ...,\n",
            "          [ 2.0325e+00,  2.0596e+00,  1.9285e+00,  ...,  4.9632e-01,\n",
            "            8.2196e-01,  8.0456e-01],\n",
            "          [ 2.1518e+00,  2.1824e+00,  1.9641e+00,  ...,  6.7781e-01,\n",
            "            4.8186e-01,  7.8287e-01],\n",
            "          [ 2.0217e+00,  1.9073e+00,  2.1068e+00,  ...,  1.3235e+00,\n",
            "            1.4944e+00,  1.6173e+00]],\n",
            "\n",
            "         [[ 2.1751e+00,  2.2289e+00,  2.1694e+00,  ...,  2.1329e+00,\n",
            "            1.9923e+00,  2.1821e+00],\n",
            "          [ 2.1710e+00,  2.1598e+00,  2.2025e+00,  ...,  1.1110e+00,\n",
            "            9.5840e-01,  1.7457e+00],\n",
            "          [ 2.1009e+00,  2.2263e+00,  2.0966e+00,  ...,  5.6140e-01,\n",
            "            7.8012e-01,  1.0828e+00],\n",
            "          ...,\n",
            "          [ 2.2318e+00,  2.0664e+00,  2.1801e+00,  ..., -3.6923e-02,\n",
            "            1.4832e-01,  6.0807e-01],\n",
            "          [ 2.2481e+00,  2.1944e+00,  2.2282e+00,  ...,  3.6223e-01,\n",
            "            1.1705e-01,  3.6710e-01],\n",
            "          [ 2.0724e+00,  2.2771e+00,  2.1486e+00,  ...,  1.0478e+00,\n",
            "            1.2619e+00,  1.8238e+00]],\n",
            "\n",
            "         [[ 2.3686e+00,  2.2571e+00,  2.4207e+00,  ...,  2.3052e+00,\n",
            "            2.3532e+00,  2.3940e+00],\n",
            "          [ 2.4636e+00,  2.3651e+00,  2.6667e+00,  ...,  1.5572e+00,\n",
            "            1.7062e+00,  2.1557e+00],\n",
            "          [ 2.3056e+00,  2.6434e+00,  2.3402e+00,  ...,  1.6684e+00,\n",
            "            1.5004e+00,  1.7893e+00],\n",
            "          ...,\n",
            "          [ 2.3843e+00,  2.2705e+00,  2.4772e+00,  ...,  8.8384e-01,\n",
            "            1.3087e+00,  1.3605e+00],\n",
            "          [ 2.3954e+00,  2.5050e+00,  2.4241e+00,  ...,  1.3066e+00,\n",
            "            1.1303e+00,  1.1782e+00],\n",
            "          [ 2.5005e+00,  2.3773e+00,  2.4213e+00,  ...,  1.7062e+00,\n",
            "            1.9620e+00,  2.0482e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4749e+00,  1.5899e+00,  1.7565e+00,  ...,  1.8470e+00,\n",
            "            2.1913e+00,  2.1124e+00],\n",
            "          [ 1.1944e+00,  9.3281e-01,  1.3294e+00,  ...,  2.0901e+00,\n",
            "            1.8639e+00,  1.9840e+00],\n",
            "          [ 1.2363e+00,  1.9981e-02, -5.4613e-01,  ...,  2.0673e+00,\n",
            "            2.1171e+00,  1.8973e+00],\n",
            "          ...,\n",
            "          [ 2.1238e+00,  1.9486e+00,  1.9921e+00,  ...,  1.6417e+00,\n",
            "            1.8212e+00,  1.9845e+00],\n",
            "          [ 1.9483e+00,  1.9160e+00,  2.0626e+00,  ...,  1.7861e+00,\n",
            "            1.8133e+00,  1.8165e+00],\n",
            "          [ 2.0481e+00,  2.2717e+00,  1.8470e+00,  ...,  1.9952e+00,\n",
            "            1.8642e+00,  1.8640e+00]],\n",
            "\n",
            "         [[ 9.5941e-01,  1.1245e+00,  1.4827e+00,  ...,  1.9617e+00,\n",
            "            2.2155e+00,  2.2674e+00],\n",
            "          [ 5.9730e-01,  1.7239e-01,  3.9532e-01,  ...,  2.0959e+00,\n",
            "            2.0360e+00,  1.9813e+00],\n",
            "          [ 8.4819e-01, -7.6651e-01, -1.0973e+00,  ...,  2.0475e+00,\n",
            "            2.1240e+00,  2.0431e+00],\n",
            "          ...,\n",
            "          [ 2.2683e+00,  2.1549e+00,  1.9754e+00,  ...,  1.5347e+00,\n",
            "            1.6965e+00,  2.0073e+00],\n",
            "          [ 1.9220e+00,  2.1755e+00,  2.1246e+00,  ...,  2.1359e+00,\n",
            "            2.1115e+00,  2.2911e+00],\n",
            "          [ 2.1340e+00,  2.1687e+00,  2.2271e+00,  ...,  2.2208e+00,\n",
            "            2.0859e+00,  2.1716e+00]],\n",
            "\n",
            "         [[ 1.4450e+00,  1.8251e+00,  1.7759e+00,  ...,  2.2953e+00,\n",
            "            2.1789e+00,  2.2406e+00],\n",
            "          [ 1.2312e+00,  8.0059e-01,  1.1224e+00,  ...,  2.1991e+00,\n",
            "            2.1952e+00,  2.4278e+00],\n",
            "          [ 1.3915e+00,  1.3019e-01, -1.4451e-01,  ...,  2.3071e+00,\n",
            "            2.2787e+00,  2.1913e+00],\n",
            "          ...,\n",
            "          [ 2.1691e+00,  2.1107e+00,  2.4279e+00,  ...,  1.9681e+00,\n",
            "            2.0657e+00,  2.2069e+00],\n",
            "          [ 2.3263e+00,  2.3792e+00,  2.4059e+00,  ...,  2.2543e+00,\n",
            "            2.5024e+00,  2.4122e+00],\n",
            "          [ 2.3180e+00,  2.3509e+00,  2.2593e+00,  ...,  2.2744e+00,\n",
            "            2.5120e+00,  2.2735e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0343e-01,  4.6343e-01,  5.5317e-01,  ...,  2.2570e-01,\n",
            "            4.8814e-01, -9.4680e-02],\n",
            "          [ 2.3140e-01,  3.7464e-02,  5.7717e-01,  ...,  5.1812e-01,\n",
            "            3.7330e-01,  1.8098e-01],\n",
            "          [ 5.1087e-01,  5.0298e-01,  4.6361e-01,  ...,  5.2952e-02,\n",
            "            1.6556e-01,  3.1944e-01],\n",
            "          ...,\n",
            "          [ 1.8732e+00,  2.1699e+00,  1.6239e+00,  ...,  6.3288e-01,\n",
            "            1.3044e+00,  1.5978e+00],\n",
            "          [ 1.7453e+00,  1.9431e+00,  1.8303e+00,  ..., -2.5300e-01,\n",
            "           -1.9731e-01, -1.6480e-01],\n",
            "          [ 1.6606e+00,  1.7615e+00,  1.8960e+00,  ...,  7.9698e-01,\n",
            "            3.4079e-01, -2.5243e-01]],\n",
            "\n",
            "         [[-8.5768e-01, -5.1623e-01, -4.3337e-01,  ..., -9.2164e-01,\n",
            "           -8.9951e-01, -1.1883e+00],\n",
            "          [-7.5129e-01, -6.4075e-01, -1.0195e-01,  ..., -9.8061e-01,\n",
            "           -8.7536e-01, -1.0045e+00],\n",
            "          [-8.3568e-01, -7.9863e-01, -4.9765e-01,  ..., -9.5023e-01,\n",
            "           -9.0564e-01, -8.9040e-01],\n",
            "          ...,\n",
            "          [ 1.9099e+00,  1.9611e+00,  1.8401e+00,  ...,  4.8645e-01,\n",
            "            7.1381e-01,  1.4870e+00],\n",
            "          [ 2.0292e+00,  1.6889e+00,  2.1577e+00,  ..., -1.1422e+00,\n",
            "           -7.1002e-01, -7.2833e-01],\n",
            "          [ 1.7085e+00,  1.7473e+00,  1.9811e+00,  ...,  1.6507e-01,\n",
            "           -1.1265e-01, -7.0949e-01]],\n",
            "\n",
            "         [[ 2.6345e-01,  2.7936e-01,  4.7571e-01,  ..., -4.2921e-03,\n",
            "           -2.8944e-01, -1.9589e-01],\n",
            "          [ 4.4825e-01,  2.5987e-01,  7.7011e-01,  ...,  8.7477e-02,\n",
            "            2.6469e-01, -1.1198e-01],\n",
            "          [ 5.3386e-01,  2.5401e-01,  1.8581e-01,  ...,  7.1825e-02,\n",
            "           -1.9391e-01, -9.3529e-02],\n",
            "          ...,\n",
            "          [ 2.2363e+00,  2.1850e+00,  2.2941e+00,  ...,  8.2189e-01,\n",
            "            1.0107e+00,  1.5008e+00],\n",
            "          [ 1.9935e+00,  2.2656e+00,  2.2351e+00,  ...,  2.9600e-01,\n",
            "            1.3458e-01,  1.8627e-01],\n",
            "          [ 2.0364e+00,  2.1634e+00,  2.2217e+00,  ...,  1.1556e+00,\n",
            "            9.1723e-01,  4.3771e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5910e+00,  1.4723e+00,  1.4758e+00,  ...,  1.7930e+00,\n",
            "            1.3666e+00,  1.2683e+00],\n",
            "          [ 1.6310e+00,  1.0808e+00,  7.9772e-01,  ...,  6.2049e-01,\n",
            "            6.7655e-01,  9.4490e-01],\n",
            "          [ 1.9309e-01,  3.1360e-01,  7.0281e-01,  ...,  3.8701e-01,\n",
            "            8.0718e-01,  7.7272e-01],\n",
            "          ...,\n",
            "          [ 1.5859e+00,  1.9392e+00,  1.8716e+00,  ...,  2.6692e-01,\n",
            "            7.7268e-01,  1.5285e+00],\n",
            "          [ 1.9372e+00,  1.8500e+00,  1.5694e+00,  ...,  8.5421e-01,\n",
            "            1.3212e+00,  6.9530e-01],\n",
            "          [ 1.8874e+00,  2.0528e+00,  1.8943e+00,  ...,  1.7779e+00,\n",
            "            1.1420e+00,  3.0524e-01]],\n",
            "\n",
            "         [[ 7.8563e-01,  2.9913e-01,  4.7318e-01,  ...,  1.3535e+00,\n",
            "            2.7846e-01,  3.4736e-01],\n",
            "          [ 3.9241e-01, -1.8376e-01, -1.8290e-02,  ..., -9.8823e-05,\n",
            "           -1.6556e-01,  1.3120e-01],\n",
            "          [-8.2321e-01, -8.6658e-01, -6.5484e-01,  ..., -2.8499e-01,\n",
            "           -4.8697e-02,  6.5962e-02],\n",
            "          ...,\n",
            "          [ 1.2955e+00,  1.9981e+00,  7.1117e-01,  ..., -5.5906e-01,\n",
            "           -2.1821e-02,  1.0777e+00],\n",
            "          [ 1.9353e+00,  1.4897e+00,  5.6494e-01,  ..., -2.1304e-02,\n",
            "            2.1314e-01, -5.4327e-01],\n",
            "          [ 2.1875e+00,  1.8873e+00,  1.7847e+00,  ...,  1.0216e+00,\n",
            "           -1.9824e-01, -8.2347e-01]],\n",
            "\n",
            "         [[ 1.5130e+00,  1.3311e+00,  1.2924e+00,  ...,  2.0168e+00,\n",
            "            1.0197e+00,  1.2272e+00],\n",
            "          [ 1.0945e+00,  8.1193e-01,  1.0310e+00,  ...,  1.0472e+00,\n",
            "            8.6435e-01,  1.1916e+00],\n",
            "          [ 3.1141e-01,  1.6308e-01,  3.9323e-01,  ...,  7.5917e-01,\n",
            "            9.9746e-01,  1.2212e+00],\n",
            "          ...,\n",
            "          [ 1.8846e+00,  2.4082e+00,  1.0576e+00,  ...,  7.6597e-01,\n",
            "            8.8833e-01,  1.7703e+00],\n",
            "          [ 2.2103e+00,  1.9718e+00,  1.3135e+00,  ...,  1.0209e+00,\n",
            "            9.7258e-01,  5.9331e-01],\n",
            "          [ 2.3394e+00,  2.3832e+00,  2.2408e+00,  ...,  1.7565e+00,\n",
            "            9.1999e-01,  5.1650e-01]]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-7e0520ce5a5c>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# MSE loss between noisy and clean images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0moptimizer_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3328\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (112) must match the size of tensor b (224) at non-singleton dimension 3"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define transformations for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the WBC dataset\n",
        "#data_dir = \"./data/WBC_1/train/data\"\n",
        "data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/WBC_1/train/data\"\n",
        "wbc_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "wbc_loader = DataLoader(wbc_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the ResNet-18 model without pretraining\n",
        "model = models.resnet18(pretrained=False).to(device)\n",
        "num_classes = len(wbc_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Define a custom dataset class for unlabeled data\n",
        "class UnlabeledDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Ensure consistent resizing for both noisy inputs and encoded outputs\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Load the unlabeled dataset (pRCC_nolabel)\n",
        "prcc_data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/pRCC_nolabel\"\n",
        "prcc_dataset = UnlabeledDataset(prcc_data_dir, transform=transform)\n",
        "prcc_loader = DataLoader(prcc_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Define the denoising autoencoder model\n",
        "class DenoisingAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenoisingAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return encoded\n",
        "\n",
        "# Initialize the denoising autoencoder model\n",
        "autoencoder = DenoisingAutoencoder().to(device)\n",
        "\n",
        "# Set up criterion (loss function) and optimizer for pretraining\n",
        "criterion_autoencoder = nn.MSELoss()\n",
        "optimizer_autoencoder = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "# Pretrain the denoising autoencoder on the unlabeled dataset\n",
        "num_epochs_autoencoder = 1  # You can adjust this\n",
        "for epoch in range(num_epochs_autoencoder):\n",
        "    autoencoder.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs in tqdm(prcc_loader, desc=f'Pretraining Epoch {epoch + 1}/{num_epochs_autoencoder}'):\n",
        "        inputs = inputs.to(device)\n",
        "        noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)  # Add random noise to the inputs\n",
        "        encoded_outputs = autoencoder(noisy_inputs)\n",
        "        print(encoded_outputs)\n",
        "        print(noisy_inputs)\n",
        "        loss = criterion_autoencoder(encoded_outputs, noisy_inputs)  # MSE loss between noisy and clean images\n",
        "        optimizer_autoencoder.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_autoencoder.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(prcc_loader)\n",
        "    print(f'Pretraining Epoch [{epoch + 1}/{num_epochs_autoencoder}], Loss: {average_loss:.4f}')\n",
        "\n",
        "# Use the encoder part of the denoising autoencoder to initialize ResNet-18 for further training\n",
        "resnet_encoder = autoencoder.encoder\n",
        "\n",
        "# Fetching Cam16 Dataset\n",
        "cam16_data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/CAM16_100cls_10mask/train/data\"\n",
        "cam16_dataset = datasets.ImageFolder(root=cam16_data_dir, transform=transform)\n",
        "cam16_loader = DataLoader(cam16_dataset, batch_size=32, shuffle=True)\n",
        "model.encoder = resnet_encoder\n",
        "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# \"\"\"\n",
        "# Training loop for CAM16 dataset\n",
        "num_epochs_cam16 = 10  # You can adjust the number of epochs as needed\n",
        "for epoch in range(num_epochs_cam16):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for inputs, labels in tqdm(cam16_loader, desc=f'Epoch {epoch + 1}/{num_epochs_cam16}'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(cam16_loader)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs_cam16}], Loss: {average_loss:.4f}')\n",
        "\n",
        "#torch.save(model.state_dict(), \"./drive/MyDrive/CS5242_project/personal_testing/pretrained_cam16_model.pth\")\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n",
        "# \"\"\"\n",
        "# Set up criterion (loss function) and optimizer\n",
        "#criterion = nn.CrossEntropyLoss().to(device)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # As needed\n",
        "\n",
        "# Single-cycle learning rate strategy\n",
        "total_iterations = len(wbc_loader) * num_epochs\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=total_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in tqdm(wbc_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(wbc_loader)\n",
        "    accuracy = (correct_predictions / total_samples) * 100\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "print(\"Training finished!\")\n",
        "\n",
        "# Define transformations for the evaluation dataset (without shuffling)\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the WBC evaluation dataset\n",
        "eval_data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/WBC_100/val/data\"\n",
        "#eval_data_dir = \"./data/WBC_100/val/data\"\n",
        "eval_dataset = datasets.ImageFolder(root=eval_data_dir, transform=eval_transform)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
        "\n",
        "# Save only the model weights\n",
        "#torch.save(model.state_dict(), './drive/MyDrive/CS5242_project/personal_testing/resnet18_WBC100.pth')\n",
        "\n",
        "# Calculate final accuracy on the evaluation dataset\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(eval_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "final_accuracy = (total_correct / total_samples) * 100\n",
        "print(f'Final Accuracy on the evaluation dataset: {final_accuracy:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}