{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06BYdN-FCU7t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06BYdN-FCU7t",
        "outputId": "0ad180f9-9e02-40b1-bbc9-13eddd0b6b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "Hmbdrt3MCr_v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmbdrt3MCr_v",
        "outputId": "a3755f6e-e553-4bdb-b857-eec940f6ac2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CAM16_100cls_10mask  pRCC_nolabel  WBC_1  WBC_10  WBC_100  WBC_50\n"
          ]
        }
      ],
      "source": [
        "!ls ./drive/MyDrive/CS5242_project/personal_testing/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54fea732-6b12-4e0c-a376-a14fadec80bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "54fea732-6b12-4e0c-a376-a14fadec80bf",
        "outputId": "710be1fa-ca71-4796-be33-d4689f1bf547"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define transformations for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the WBC dataset\n",
        "#data_dir = \"./data/WBC_1/train/data\"\n",
        "data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/WBC_1/train/data\"\n",
        "wbc_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "wbc_loader = DataLoader(wbc_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the ResNet-18 model without pretraining\n",
        "model = models.resnet18(pretrained=False).to(device)\n",
        "num_classes = len(wbc_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Define a custom dataset class for unlabeled data\n",
        "class UnlabeledDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Ensure consistent resizing for both noisy inputs and encoded outputs\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Load the unlabeled dataset (pRCC_nolabel)\n",
        "prcc_data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/pRCC_nolabel\"\n",
        "prcc_dataset = UnlabeledDataset(prcc_data_dir, transform=transform)\n",
        "prcc_loader = DataLoader(prcc_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Define the denoising autoencoder model\n",
        "class DenoisingAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenoisingAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return encoded\n",
        "\n",
        "# Initialize the denoising autoencoder model\n",
        "autoencoder = DenoisingAutoencoder().to(device)\n",
        "\n",
        "# Set up criterion (loss function) and optimizer for pretraining\n",
        "criterion_autoencoder = nn.MSELoss()\n",
        "optimizer_autoencoder = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "# Pretrain the denoising autoencoder on the unlabeled dataset\n",
        "num_epochs_autoencoder = 1  # You can adjust this\n",
        "for epoch in range(num_epochs_autoencoder):\n",
        "    autoencoder.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs in tqdm(prcc_loader, desc=f'Pretraining Epoch {epoch + 1}/{num_epochs_autoencoder}'):\n",
        "        inputs = inputs.to(device)\n",
        "        noisy_inputs = inputs + 0.1 * torch.randn_like(inputs)  # Add random noise to the inputs\n",
        "        encoded_outputs = autoencoder(noisy_inputs)\n",
        "        print(encoded_outputs)\n",
        "        print(noisy_inputs)\n",
        "        loss = criterion_autoencoder(encoded_outputs, noisy_inputs)  # MSE loss between noisy and clean images\n",
        "        optimizer_autoencoder.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_autoencoder.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(prcc_loader)\n",
        "    print(f'Pretraining Epoch [{epoch + 1}/{num_epochs_autoencoder}], Loss: {average_loss:.4f}')\n",
        "\n",
        "# Use the encoder part of the denoising autoencoder to initialize ResNet-18 for further training\n",
        "resnet_encoder = autoencoder.encoder\n",
        "\n",
        "# Fetching Cam16 Dataset\n",
        "cam16_data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/CAM16_100cls_10mask/train/data\"\n",
        "cam16_dataset = datasets.ImageFolder(root=cam16_data_dir, transform=transform)\n",
        "cam16_loader = DataLoader(cam16_dataset, batch_size=32, shuffle=True)\n",
        "model.encoder = resnet_encoder\n",
        "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# \"\"\"\n",
        "# Training loop for CAM16 dataset\n",
        "num_epochs_cam16 = 10  # You can adjust the number of epochs as needed\n",
        "for epoch in range(num_epochs_cam16):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for inputs, labels in tqdm(cam16_loader, desc=f'Epoch {epoch + 1}/{num_epochs_cam16}'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(cam16_loader)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs_cam16}], Loss: {average_loss:.4f}')\n",
        "\n",
        "#torch.save(model.state_dict(), \"./drive/MyDrive/CS5242_project/personal_testing/pretrained_cam16_model.pth\")\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n",
        "# \"\"\"\n",
        "# Set up criterion (loss function) and optimizer\n",
        "#criterion = nn.CrossEntropyLoss().to(device)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # As needed\n",
        "\n",
        "# Single-cycle learning rate strategy\n",
        "total_iterations = len(wbc_loader) * num_epochs\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=total_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in tqdm(wbc_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(wbc_loader)\n",
        "    accuracy = (correct_predictions / total_samples) * 100\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "print(\"Training finished!\")\n",
        "\n",
        "# Define transformations for the evaluation dataset (without shuffling)\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the WBC evaluation dataset\n",
        "eval_data_dir = \"./drive/MyDrive/CS5242_project/personal_testing/data/WBC_100/val/data\"\n",
        "#eval_data_dir = \"./data/WBC_100/val/data\"\n",
        "eval_dataset = datasets.ImageFolder(root=eval_data_dir, transform=eval_transform)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
        "\n",
        "# Save only the model weights\n",
        "#torch.save(model.state_dict(), './drive/MyDrive/CS5242_project/personal_testing/resnet18_WBC100.pth')\n",
        "\n",
        "# Calculate final accuracy on the evaluation dataset\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(eval_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "final_accuracy = (total_correct / total_samples) * 100\n",
        "print(f'Final Accuracy on the evaluation dataset: {final_accuracy:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
